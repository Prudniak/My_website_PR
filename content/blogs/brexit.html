---
categories:  
- ""   
- ""
date: "2022-09-13"
description: Brexit vote analysis
draft: false
image: pic_p04.jpg 

keywords: ""
slug: brexit 
title: Brexit analysis
---



<div id="climate-change-and-temperature-anomalies" class="section level1">
<h1>Climate change and temperature anomalies</h1>
<p>If we wanted to study climate change, we can find data on the <em>Combined
Land-Surface Air and Sea-Surface Water Temperature Anomalies</em> in the
Northern Hemisphere at <a href="https://data.giss.nasa.gov/gistemp">NASA’s Goddard Institute for Space
Studies</a>. The <a href="https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt">tabular data of
temperature anomalies can be found
here</a></p>
<p>To define temperature anomalies you need to have a reference, or base,
period which NASA clearly states that it is the period between
1951-1980.</p>
<pre class="r"><code>weather &lt;- 
  read_csv(&quot;https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv&quot;, 
           skip = 1, 
           na = &quot;***&quot;)</code></pre>
<p>For each month and year, the dataframe shows the deviation of
temperature from the normal (expected). Further the dataframe is in wide
format.</p>
<p><strong>Cleaning Data</strong></p>
<pre class="r"><code>tidyweather &lt;- weather %&gt;% 
  select(1:13) %&gt;% 
  pivot_longer( cols = 2:13,
                names_to = &quot;Month&quot;,
                values_to = &quot;delta&quot;)

glimpse(tidyweather)</code></pre>
<pre><code>## Rows: 1,716
## Columns: 3
## $ Year  &lt;dbl&gt; 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880…
## $ Month &lt;chr&gt; &quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;…
## $ delta &lt;dbl&gt; -0.36, -0.50, -0.23, -0.29, -0.06, -0.16, -0.17, -0.25, -0.22, -…</code></pre>
<div id="plotting-information" class="section level2">
<h2>Plotting Information</h2>
<p>Plotting data using a time-series scatterplot with a trendline.</p>
<pre class="r"><code>tidyweather &lt;- tidyweather %&gt;%
  mutate(date = ymd(paste(as.character(Year), Month, &quot;1&quot;)),
         month = month(date, label=TRUE),
         year = year(date))

ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color=&quot;red&quot;) +
  theme_bw() +
  labs (
    title = &quot;Weather Anomalies&quot;,
    x = &quot;Year&quot;,
    y = &quot;Temperature deviaton&quot;,
    caption = &quot;Source: https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt&quot;
  ) +
  NULL</code></pre>
<p><img src="/blogs/brexit_files/figure-html/scatter_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Producing a scatter plot showing the temperature anomalies by month.</p>
<pre class="r"><code>ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color=&quot;red&quot;) +
  theme_bw() +
  labs (
    title = &quot;Weather Anomalies&quot;,
    x = &quot;Year&quot;,
    y = &quot;Temperature deviaton&quot;,
    caption = &quot;Source: https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt&quot;
  ) +
  facet_wrap(~month) +
  NULL</code></pre>
<p><img src="/blogs/brexit_files/figure-html/facet_wrap-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Grouping data into different time periods to study historical data.</p>
<pre class="r"><code>comparison &lt;- tidyweather %&gt;% 
  filter(Year&gt;= 1881) %&gt;%     #remove years prior to 1881
  #create new variable &#39;interval&#39;, and assign values based on criteria below:
  mutate(interval = case_when(
    Year %in% c(1881:1920) ~ &quot;1881-1920&quot;,
    Year %in% c(1921:1950) ~ &quot;1921-1950&quot;,
    Year %in% c(1951:1980) ~ &quot;1951-1980&quot;,
    Year %in% c(1981:2010) ~ &quot;1981-2010&quot;,
    TRUE ~ &quot;2011-present&quot;
  ))

comparison</code></pre>
<pre><code>## # A tibble: 1,704 × 7
##     Year Month delta date       month  year interval 
##    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;date&gt;     &lt;ord&gt; &lt;dbl&gt; &lt;chr&gt;    
##  1  1881 Jan   -0.3  1881-01-01 Jan    1881 1881-1920
##  2  1881 Feb   -0.21 1881-02-01 Feb    1881 1881-1920
##  3  1881 Mar   -0.03 1881-03-01 Mar    1881 1881-1920
##  4  1881 Apr    0.01 1881-04-01 Apr    1881 1881-1920
##  5  1881 May    0.05 1881-05-01 May    1881 1881-1920
##  6  1881 Jun   -0.32 1881-06-01 Jun    1881 1881-1920
##  7  1881 Jul    0.09 1881-07-01 Jul    1881 1881-1920
##  8  1881 Aug   -0.03 1881-08-01 Aug    1881 1881-1920
##  9  1881 Sep   -0.26 1881-09-01 Sep    1881 1881-1920
## 10  1881 Oct   -0.43 1881-10-01 Oct    1881 1881-1920
## # … with 1,694 more rows</code></pre>
<p>Creating a density plot to study the distribution of monthly deviations
grouped by the different time periods.</p>
<pre class="r"><code>ggplot(data = comparison, aes(delta)) +
  geom_density(aes(fill = interval), alpha = 1/4) +
  labs(title = &quot;Distribution of Monthly Temperature Anomalies in Time Intervals&quot;,
       x = &quot;Monthly Temperature Anomaly&quot;, 
       y = &quot;Density&quot;,
    caption = &quot;Source: https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt&quot;) +
  facet_wrap(~ interval, ncol = 1) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;) +
  NULL</code></pre>
<p><img src="/blogs/brexit_files/figure-html/density_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Calculating average annual anomalies.</p>
<pre class="r"><code>#creating yearly averages
average_annual_anomaly &lt;- tidyweather %&gt;% 
  group_by(Year) %&gt;%   #grouping data by Year
  
  # creating summaries for mean delta 
  summarise(mean_delta = mean(delta, na.rm=TRUE))

#plotting the data:

ggplot(average_annual_anomaly, 
       aes (x = Year,
            y = mean_delta)) +
  geom_point() +
  theme_bw() +
  geom_smooth(method = &quot;loess&quot;) +
  labs(title = &quot;Average annual anomalies by year&quot;,
       y = &quot;Average annual anomalies&quot;,
    caption = &quot;Source: https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt&quot;) +
  NULL</code></pre>
<p><img src="/blogs/brexit_files/figure-html/averaging-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="confidence-interval-for-delta" class="section level2">
<h2>Confidence Interval for <code>delta</code></h2>
<p><a href="https://earthobservatory.nasa.gov/world-of-change/decadaltemp.php">NASA points out on their
website</a>
that</p>
<blockquote>
<p>A one-degree global change is significant because it takes a vast
amount of heat to warm all the oceans, atmosphere, and land by that
much. In the past, a one- to two-degree drop was all it took to plunge
the Earth into the Little Ice Age.</p>
</blockquote>
<p>Construction of a confidence interval for the average annual delta since
2011, both using a formula and using a bootstrap simulation with the
<code>infer</code> package.</p>
<pre class="r"><code>formula_ci &lt;- comparison %&gt;% 
  filter(interval == &quot;2011-present&quot;) %&gt;% # choose the interval 2011-present
  filter(!delta == &quot;NA&quot;) %&gt;% # drop NA observations in delta
  summarise(count = n(),
            t = qt(0.975, count-1), # use qt with probability and degrees of freedom
            mean = mean(delta), # calculate mean
            sd = sd(delta), # calculate sd
            se = sd(delta)/sqrt(count), # calculate se
            margin = t * se, # calculate margin of error
            lower = mean - margin, # calculate lower bound
            upper = mean + margin #calculate upper bound
            
  )

#print out formula_CI
formula_ci</code></pre>
<pre><code>## # A tibble: 1 × 8
##   count     t  mean    sd     se margin lower upper
##   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1   139  1.98  1.07 0.266 0.0226 0.0446  1.02  1.11</code></pre>
<pre class="r"><code>library(infer)

set.seed(1234)

boot_ci &lt;- comparison %&gt;% 
  filter(interval == &quot;2011-present&quot;) %&gt;% # choose the interval 2011-present
  filter(!delta == &quot;NA&quot;) %&gt;% # drop NA observations in delta
  specify(response = delta) %&gt;% # specify the variable of interest
  generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% # extract 1000 bootstrap samples
  calculate(stat = &quot;mean&quot;) %&gt;% # calculate sample means from each bootstrap sample
  get_confidence_interval(level = 0.95, type = &quot;percentile&quot;) # calculate confidence interval of this analysis

# Display confidence interval
boot_ci</code></pre>
<pre><code>## # A tibble: 1 × 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1     1.02     1.11</code></pre>
<blockquote>
<p>Two different methods of constructing 95% confidence interval were
used in this example. First was based on filtering appropriate
interval and calculating confidence interval using summary statistics.
Second involved ‘infer’ package, which allowed to use bootstrap method
and produced the confidence intervals without any additional summary
statistics. According to the summary calculations the average annual
anomalies since 2011 already exceeded 1 degree, even when 95%
confidence interval is taken into account. Therefore, it is highly
likely that anomalies will become even more frequent and significant
than before.</p>
</blockquote>
</div>
</div>
<div id="bidens-approval-margins" class="section level1">
<h1>Biden’s Approval Margins</h1>
<p>As we saw in class, fivethirtyeight.com has detailed data on <a href="https://projects.fivethirtyeight.com/biden-approval-ratings">all polls
that track the president’s
approval</a></p>
<pre class="r"><code># Import approval polls data directly off fivethirtyeight website
approval_pollist &lt;- read_csv(&#39;https://projects.fivethirtyeight.com/biden-approval-data/approval_polllist.csv&#39;) 

#fixing dates using &#39;lubridate&#39; package
approval_pollist &lt;- approval_pollist %&gt;% 
  mutate(modeldate = mdy(modeldate),
         startdate = mdy(startdate),
         enddate = mdy(enddate),
         year = year(enddate),
         week_number = week(enddate))

glimpse(approval_pollist)</code></pre>
<pre><code>## Rows: 4,522
## Columns: 24
## $ president           &lt;chr&gt; &quot;Joe Biden&quot;, &quot;Joe Biden&quot;, &quot;Joe Biden&quot;, &quot;Joe Biden&quot;…
## $ subgroup            &lt;chr&gt; &quot;All polls&quot;, &quot;All polls&quot;, &quot;All polls&quot;, &quot;All polls&quot;…
## $ modeldate           &lt;date&gt; 2022-09-13, 2022-09-13, 2022-09-13, 2022-09-13, 2…
## $ startdate           &lt;date&gt; 2021-01-19, 2021-01-19, 2021-01-20, 2021-01-20, 2…
## $ enddate             &lt;date&gt; 2021-01-21, 2021-01-21, 2021-01-21, 2021-01-22, 2…
## $ pollster            &lt;chr&gt; &quot;Morning Consult&quot;, &quot;Rasmussen Reports/Pulse Opinio…
## $ grade               &lt;chr&gt; &quot;B&quot;, &quot;B&quot;, &quot;B-&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B+&quot;, &quot;B+&quot;, &quot;B-&quot;, &quot;B&quot;, &quot;…
## $ samplesize          &lt;dbl&gt; 15000, 1500, 1115, 15000, 1993, 1516, 941, 1200, 1…
## $ population          &lt;chr&gt; &quot;a&quot;, &quot;lv&quot;, &quot;a&quot;, &quot;a&quot;, &quot;rv&quot;, &quot;a&quot;, &quot;rv&quot;, &quot;rv&quot;, &quot;a&quot;, &quot;…
## $ weight              &lt;dbl&gt; 0.2594, 0.3382, 1.1014, 0.2333, 0.0930, 1.2454, 1.…
## $ influence           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ approve             &lt;dbl&gt; 50.0, 48.0, 55.5, 51.0, 56.0, 45.0, 63.0, 58.0, 52…
## $ disapprove          &lt;dbl&gt; 28.0, 45.0, 31.6, 28.0, 31.0, 28.0, 37.0, 32.0, 29…
## $ adjusted_approve    &lt;dbl&gt; 49.4, 49.2, 54.6, 50.4, 55.4, 46.1, 59.5, 57.5, 51…
## $ adjusted_disapprove &lt;dbl&gt; 30.9, 40.3, 32.5, 30.9, 33.9, 29.0, 38.4, 32.8, 31…
## $ multiversions       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ tracking            &lt;lgl&gt; TRUE, TRUE, NA, TRUE, NA, NA, NA, NA, TRUE, TRUE, …
## $ url                 &lt;chr&gt; &quot;https://morningconsult.com/form/global-leader-app…
## $ poll_id             &lt;dbl&gt; 74272, 74247, 74248, 74273, 74246, 74327, 74256, 7…
## $ question_id         &lt;dbl&gt; 139491, 139395, 139404, 139492, 139394, 139570, 13…
## $ createddate         &lt;chr&gt; &quot;1/28/2021&quot;, &quot;1/22/2021&quot;, &quot;1/22/2021&quot;, &quot;1/28/2021&quot;…
## $ timestamp           &lt;chr&gt; &quot;10:03:31 13 Sep 2022&quot;, &quot;10:03:31 13 Sep 2022&quot;, &quot;1…
## $ year                &lt;dbl&gt; 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 20…
## $ week_number         &lt;dbl&gt; 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…</code></pre>
<div id="create-a-plot" class="section level2">
<h2>Create a plot</h2>
<p>Calculating the average net approval rate (approve- disapprove) for each
week since Biden got into office and plotting the net approval for each
week in 2022, along with its 95% confidence interval.</p>
<pre class="r"><code>biden_plot &lt;- approval_pollist %&gt;% 
  
  # filtering 2007 year
  filter(year == &quot;2022&quot;) %&gt;% 
  
  # adding new column with difference between approve and disapprove
  mutate(net_approval = approve - disapprove) %&gt;% 
  
  # grouping by subgroup and number of the week
  group_by(subgroup, week_number)  %&gt;% 
  
  # calculating summary statistics needed for 95% confidence interval
  summarise(mean_net = mean(net_approval), #mean
            sd_net = sd(net_approval), #standard devation
            count = n(), #number of observations
            t_critical = qt(0.975, count-1), #t statistic
            se_net = sd_net / sqrt(count), #standard error
            margin_of_error = t_critical * se_net, #margin of error
            net_low = mean_net - margin_of_error, #lower part of confidence interval
            net_high = mean_net + margin_of_error) #upper part of confidence interval


# Creating plot
ggplot(biden_plot, 
       aes(x = week_number,
           y = mean_net,
           color = subgroup)) +
  geom_line(size = 1.05) + 
  geom_ribbon(aes(ymin = net_low,
                  ymax = net_high,
                  alpha = 200),
              fill = &quot;#F7E1AD&quot;,
              size = 1.05) +
  facet_grid(rows = vars(subgroup)) +
   labs(title = &quot;Biden&#39;s Net Approval Ratings in 2022&quot;,
        subtitle = &quot;Weekly Data, Approve - Disapprove, %&quot;,
        caption = &quot;Source: https://projects.fivethirtyeight.com/biden-approval-data&quot;,
       x = &quot;Week in 2022&quot;, 
       y = NULL) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;) +
  NULL</code></pre>
<p><img src="/blogs/brexit_files/figure-html/trump_margins-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="challenge-1-excess-rentals-in-tfl-bike-sharing" class="section level1">
<h1>Challenge 1: Excess rentals in TfL bike sharing</h1>
<p>Loading data</p>
<pre class="r"><code>url &lt;- &quot;https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx&quot;

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp &lt;- tempfile(fileext = &quot;.xlsx&quot;)))</code></pre>
<pre><code>## Response [https://airdrive-secure.s3-eu-west-1.amazonaws.com/london/dataset/number-bicycle-hires/2022-09-06T12%3A41%3A48/tfl-daily-cycle-hires.xlsx?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAJJDIMAIVZJDICKHA%2F20220913%2Feu-west-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20220913T142023Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=80d1d2b9e48fc37f5b099e8a1312cd20d20bf1d9b025a7243c5831a0b285a505&amp;X-Amz-SignedHeaders=host]
##   Date: 2022-09-13 14:20
##   Status: 200
##   Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
##   Size: 180 kB
## &lt;ON DISK&gt;  C:\Users\prudn\AppData\Local\Temp\RtmpAbfkVF\file326c4fb86cc2.xlsx</code></pre>
<pre class="r"><code># Use read_excel to read it as dataframe
bike0 &lt;- read_excel(bike.temp,
                   sheet = &quot;Data&quot;,
                   range = cell_cols(&quot;A:B&quot;))

# change dates to get year, month, and week
bike &lt;- bike0 %&gt;% 
  clean_names() %&gt;% 
  rename (bikes_hired = number_of_bicycle_hires) %&gt;% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = week(day))</code></pre>
<p>Creating a facet grid that plots bikes hired by month and year since
2015</p>
<pre class="r"><code>bike %&gt;% 
  
  #filtering 2015-present
  filter(year &gt;= 2015) %&gt;% 
  
  #creating plot
  ggplot(aes(x = bikes_hired)) +
  geom_density() +
  facet_grid(rows = vars(year),
             cols = vars(month)) +
  labs(title = &quot;Distribution of bikes hired per month&quot;,
       x = &quot;Bike rentals&quot;, 
       y = NULL,
       caption = &quot;Source: https://data.london.gov.uk/dataset/number-bicycle-hires&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;none&quot;,
        axis.text.y = element_blank()) +
  scale_x_continuous(labels = label_number(suffix = &quot;K&quot;, scale = 1e-3)) +
  NULL</code></pre>
<p><img src="/blogs/brexit_files/figure-html/tfl_month_year_grid-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Plotting monthly changes in TfL bike rentals.</p>
<pre class="r"><code>#calculating average for 2016-2019 period
bike1 &lt;- bike %&gt;%
  filter(year %in% c(&quot;2016&quot;,&quot;2017&quot;,&quot;2018&quot;,&quot;2019&quot;)) %&gt;%
  group_by(month) %&gt;%
  summarise(monthly_hired = mean(bikes_hired))

#calculating means for 2017-2022 years
bike2 &lt;- bike %&gt;%
  filter(year %in% c(2017:2022)) %&gt;%
  group_by(month,year) %&gt;%
  summarise(mean_bikes_hired = mean(bikes_hired))

#merging two datasets
bike_coord1 &lt;- merge(bike2, bike1, all.x=T)


#adding new column that chooses smaller value from the mean_bikes_hired &amp; monthly_hired columns
bike_coord1 &lt;- bike_coord1 %&gt;% 
  mutate(min_1 = pmin(mean_bikes_hired,monthly_hired))
  
#creating the plot
ggplot(bike_coord1,aes(x=month,y=monthly_hired)) +
  geom_line(aes(group=1),
            color=&quot;#0000FF&quot;, 
            size = 1.2) +
  geom_line(data=bike_coord1,
            aes(month,mean_bikes_hired),
            group=1, 
            size = 1.05,
            color = &quot;#000000&quot;) +
  geom_ribbon(aes(ymin=min_1, 
                  ymax = mean_bikes_hired, 
                  group=year), 
              fill = &quot;#00CC00&quot;, 
              alpha = 0.4) +
  geom_ribbon(aes(ymin=min_1, 
                  ymax = monthly_hired, 
                  group=year), 
              fill = &quot;#FF0000&quot;, 
              alpha = 0.4) +
  facet_wrap(~year) +
  theme_minimal() +
  theme(legend.position = &quot;none&quot;) +
  labs(title = &quot;Monthly changes in TfL bike rentals&quot;, 
       subtitle = &quot;Change from monthly average shown in blue and calculated between 2016-2019&quot;, 
       x = &quot;Months&quot;, 
       y = &quot;Bike rentals&quot;,
       caption = &quot;Source: https://data.london.gov.uk/dataset/number-bicycle-hires&quot;) +
  NULL</code></pre>
<p><img src="/blogs/brexit_files/figure-html/tfl_absolute_monthly_change-1.png" width="100%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Number of rented bikes in years 2017-2019 is close to the average
calculated between 2016-2019. However, since 2020 clear influence of
COVID pandemic and lockdowns is visible. First, in spring of 2020
there is huge decline, as most people stayed at home. After initial
lockdown more and more people decided to switch to bikes from other
means of transportation. It seems that people that switch to bikes
decided not to come back to their old habits after restrictions were
lifted as bike rentals in 2022 in every month exceed average from
2016-2019.</p>
</blockquote>
<p>Plotting percentage changes from the expected level of weekly rentals of
TfL bikes.</p>
<pre class="r"><code>#calculating weekly average for 2016-2019 period
bike3 &lt;- bike %&gt;%
  filter(year %in% c(&quot;2016&quot;,&quot;2017&quot;,&quot;2018&quot;,&quot;2019&quot;)) %&gt;%
  group_by(week) %&gt;%
  summarise(weekly_hired = mean(bikes_hired))

#calculating weekly means for 2017-2022 period
bike4 &lt;- bike %&gt;%
  filter(year %in% c(2017:2022)) %&gt;%
  group_by(week,year) %&gt;%
  summarise(mean_bikes_hired = mean(bikes_hired))


#merging two datasets
bike_coord2 &lt;- merge(bike4, bike3, all.x=T)


bike_coord2 &lt;- bike_coord2 %&gt;% 
  #calculating percentage change
  mutate(percent_change=(mean_bikes_hired-weekly_hired)/weekly_hired,
         #adding two columns 1) with values lower than zero + 0, and 2) with values greater than zero + 0
         min_1=pmin(percent_change,0),
         max_1=pmax(percent_change,0),
         #adding class to values depending on whether the values are positive or negative
         class = as.factor(ifelse(percent_change &gt;= 0, &quot;positive&quot;, &quot;negative&quot;)))
  

#creating plot
ggplot(bike_coord2,aes(x=week,y=percent_change)) +
   annotate(&quot;rect&quot;, 
           xmin = 14, 
           xmax = 26,
           ymin = -0.5, 
           ymax = 1,
           fill = &quot;#E0E0E0&quot;, 
           alpha = 0.7) +
  annotate(&quot;rect&quot;, 
           xmin = 40, 
           xmax = 52,
           ymin = -0.5, 
           ymax = 1,
           fill = &quot;#E0E0E0&quot;, 
           alpha = 0.7) +
  geom_line(aes(group=1),
            size = 1.05,
            color = &quot;#000000&quot;) +
  geom_ribbon(aes(ymin=min_1,
                  ymax=percent_change,
                  group=year),
              fill=&quot;#00CC00&quot;, 
              alpha=0.25) +
  geom_ribbon(aes(ymin=percent_change, 
                  ymax=max_1,
                  group=year),
              fill=&quot;#FF0000&quot;, 
              alpha=0.25) +
  geom_rug(sides = &quot;b&quot;,
           aes(color = class)) +
  scale_color_manual(values = c(&quot;#FF0000&quot;, &quot;#00CC00&quot;)) +
  facet_wrap(~year) +
  theme_minimal() +
  theme(legend.position = &quot;none&quot;) +
  labs(title = &quot;Weekly changes in TfL bike rentals&quot;, 
       subtitle = &quot;% change from weekly averages shown 
  calculated between 2016-2019&quot;, 
       x = &quot;Weeks&quot;, 
       y = &quot;Bike rentals&quot;,
       caption = &quot;Source: https://data.london.gov.uk/dataset/number-bicycle-hires&quot;) +
  scale_y_continuous(labels = scales::percent) +
  NULL</code></pre>
<p><img src="/blogs/brexit_files/figure-html/tfl_percent_change-1.png" width="100%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Weekly % changes supports conclusions from the first graph. Moreover,
the impact of the lockdowns in spring of 2020 and winter of 2021 are
much better visible.</p>
</blockquote>
</div>
<div id="challenge-2-share-of-renewable-energy-production-in-the-world" class="section level1">
<h1>Challenge 2: Share of renewable energy production in the world</h1>
<p>The National Bureau of Economic Research (NBER) has a a very interesting
dataset on the adoption of about 200 technologies in more than 150
countries since 1800. This is the<a href="https://www.nber.org/research/data/cross-country-historical-adoption-technology">Cross-country Historical Adoption of
Technology (CHAT)
dataset</a>.</p>
<p>The following is a description of the variables</p>
<table>
<thead>
<tr class="header">
<th><strong>variable</strong></th>
<th><strong>class</strong></th>
<th><strong>description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>variable</td>
<td>character</td>
<td>Variable name</td>
</tr>
<tr class="even">
<td>label</td>
<td>character</td>
<td>Label for variable</td>
</tr>
<tr class="odd">
<td>iso3c</td>
<td>character</td>
<td>Country code</td>
</tr>
<tr class="even">
<td>year</td>
<td>double</td>
<td>Year</td>
</tr>
<tr class="odd">
<td>group</td>
<td>character</td>
<td>Group (consumption/production)</td>
</tr>
<tr class="even">
<td>category</td>
<td>character</td>
<td>Category</td>
</tr>
<tr class="odd">
<td>value</td>
<td>double</td>
<td>Value (related to label)</td>
</tr>
</tbody>
</table>
<pre class="r"><code>technology &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-07-19/technology.csv&#39;)

#get all technologies
labels &lt;- technology %&gt;% 
  distinct(variable, label)

# Get country names using &#39;countrycode&#39; package
technology &lt;- technology %&gt;% 
  filter(iso3c != &quot;XCD&quot;) %&gt;% 
  mutate(iso3c = recode(iso3c, &quot;ROM&quot; = &quot;ROU&quot;),
         country = countrycode(iso3c, origin = &quot;iso3c&quot;, destination = &quot;country.name&quot;),
         country = case_when(
           iso3c == &quot;ANT&quot; ~ &quot;Netherlands Antilles&quot;,
           iso3c == &quot;CSK&quot; ~ &quot;Czechoslovakia&quot;,
           iso3c == &quot;XKX&quot; ~ &quot;Kosovo&quot;,
           TRUE           ~ country))

#make smaller dataframe on energy
energy &lt;- technology %&gt;% 
  filter(category == &quot;Energy&quot;)

# download CO2 per capita from World Bank using {wbstats} package
# https://data.worldbank.org/indicator/EN.ATM.CO2E.PC
co2_percap &lt;- wb_data(country = &quot;countries_only&quot;, 
                      indicator = &quot;EN.ATM.CO2E.PC&quot;, 
                      start_date = 1970, 
                      end_date = 2022,
                      return_wide=FALSE) %&gt;% 
  filter(!is.na(value)) %&gt;% 
  #drop unwanted variables
  select(-c(unit, obs_status, footnote, last_updated))

# get a list of countries and their characteristics
# we just want to get the region a country is in and its income level
countries &lt;-  wb_cachelist$countries %&gt;% 
  select(iso3c,region,income_level)</code></pre>
<p>Creating of a graph with the countries with the highest and lowest %
contribution of renewables in energy production.</p>
<pre class="r"><code>energy &lt;- energy %&gt;% 
  
  #filteting out the NAs
  filter(!is.na(value))

#Top 20 countries with highest % contribution of renewables in energy production

top_res &lt;- energy %&gt;% 
  
  # dropping unnessecary columns
  select(-c(label, iso3c, group, category)) %&gt;% 
  
  #pivoting dataset wider
  pivot_wider(names_from = &quot;variable&quot;,
              values_from = &quot;value&quot;) %&gt;% 
  
  #filtering year 2019
  filter(year == 2019) %&gt;% 
  
  #grouping by country
  group_by(country) %&gt;% 
  
  #calculating the % of renewables in energy production
  summarise(total_res_perc = sum(elec_hydro, elec_solar, elec_wind, elec_renew_other)/ sum(elecprod)) %&gt;% 
  
  #arranging in descending order 
  arrange(desc(total_res_perc)) %&gt;% 
  
  #choosing top 20 countries
  head(20)


#Creating plot with Top 20 countries with highest % contribution of renewables in energy production

top_res_plot &lt;- ggplot(top_res, 
       aes(x = total_res_perc, 
           y = fct_reorder(country, total_res_perc))) +
  geom_col() +
     labs(subtitle = &quot;Highest&quot;,
       x = NULL, 
       y = NULL) +
  theme_light() +
  theme(legend.position = &quot;none&quot;) +
  scale_x_continuous(labels = scales::percent) +
  NULL


#Top 20 countries with lowest % contribution of renewables in energy production

bot_res &lt;- energy %&gt;% 
  
  # dropping unnessecary columns
  select(-c(label, iso3c, group, category)) %&gt;% 
  
  #pivoting dataset wider
  pivot_wider(names_from = &quot;variable&quot;,
              values_from = &quot;value&quot;) %&gt;% 
  
  #filtering year 2019
  filter(year == 2019) %&gt;% 
  
  #grouping by country
  group_by(country) %&gt;% 
  
  #calculating the % of renewables in energy production
  summarise(total_res_perc = sum(elec_hydro, elec_solar, elec_wind, elec_renew_other)/ sum(elecprod)) %&gt;% 
  
  #arranging in ascending order 
  arrange(total_res_perc) %&gt;% 
  
  #choosing top 20 countries
  head(20)


#Creating plot with Top 20 countries with lowest % contribution of renewables in energy production

bot_res_plot &lt;- ggplot(bot_res, 
       aes(x = total_res_perc, 
           y = fct_reorder(country, total_res_perc))) +
  geom_col() +
     labs(subtitle = &quot;Lowest&quot;,
       x = NULL, 
       y = NULL) +
  theme_light() +
  theme(legend.position = &quot;none&quot;) +
  scale_x_continuous(labels = scales::percent) +
  NULL



#joining two plots together with &#39;patchwork&#39;

res_plot &lt;- top_res_plot / bot_res_plot + 
  plot_annotation(title = &quot;Highest and lowest % of renewables in energy production&quot;,
                  subtitle = &quot;2019 data&quot;,
                  caption = &quot;Source: NBER CHAT Database&quot;) 

res_plot</code></pre>
<p><img src="/blogs/brexit_files/figure-html/min-max_renewables-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Creating an animation to explore the relationship between CO2 per capita
emissions and the deployment of renewables.</p>
<pre class="r"><code>energy_plot &lt;- energy_new %&gt;% 
  
  #filtering year &amp; NAs
  filter(year &gt;= 1991) %&gt;% 
  filter(!is.na(income_level)) %&gt;% 
  
  #grouping by country and year
  group_by(country, year, income_level) %&gt;% 
  
  #calculating the % of renewables in energy production
  summarise(total_res_perc = sum(elec_hydro, elec_solar, elec_wind, elec_renew_other)/ sum(elecprod),
        emissions = CO2_emissions) 

#creating plot
p &lt;- ggplot(energy_plot, 
       aes(x = total_res_perc,
           y = emissions,
           color = income_level)) +
  geom_point() +
  labs(title = &#39;Year: {as.integer(frame_time)}&#39;, 
           x = &#39;% of renewables&#39;, 
           y = &#39;CO2 per cap&#39;,
       caption = &quot;Source: NBER CHAT Database&quot;) +
  transition_time(year) +
  ease_aes(&#39;linear&#39;) +
  facet_wrap(~income_level, ncol = 2) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;) +
  scale_x_continuous(labels = scales::percent) +
  NULL

  
animate(p) </code></pre>
<p><img src="/blogs/brexit_files/figure-html/plotting-1.gif" style="display: block; margin: auto;" /></p>
<blockquote>
<p>In every income group, it seems that % of renewables in energy
production is negatively correlated with the amount of CO2 emitted per
capita. Therefore, investing in such energy sources could be leveraged
to achieve net zero strategies by countries all over the world.</p>
</blockquote>
</div>
<div id="deliverables" class="section level1">
<h1>Deliverables</h1>
<p>As usual, there is a lot of explanatory text, comments, etc. You do not
need these, so delete them and produce a stand-alone document that you
could share with someone. Knit the edited and completed R Markdown file
as an HTML document (use the “Knit” button at the top of the script
editor window) and upload it to Canvas.</p>
</div>
<div id="details" class="section level1">
<h1>Details</h1>
<ul>
<li>Who did you collaborate with: Neha Dagade, Piotr Rudniak, Jomal
Jochan, Mingqi Yin, Gian Marco Serra, Lucia Cai</li>
<li>Approximately how much time did you spend on this problem set:
ANSWER HERE</li>
<li>What, if anything, gave you the most trouble: ANSWER HERE</li>
</ul>
<p><strong>Please seek out help when you need it,</strong> and remember the <a href="https://mam202.netlify.app/syllabus/#the-15-minute-rule" target="_blank">15-minute
rule</a>.
You know enough R (and have enough examples of code from class and your
readings) to be able to do this. If you get stuck, ask for help from
others, post a question on Slack– and remember that I am here to help
too!</p>
<blockquote>
<p>As a true test to yourself, do you understand the code you submitted
and are you able to explain it to someone else?</p>
</blockquote>
</div>
<div id="rubric" class="section level1">
<h1>Rubric</h1>
<p>Check minus (1/5): Displays minimal effort. Doesn’t complete all
components. Code is poorly written and not documented. Uses the same
type of plot for each graph, or doesn’t use plots appropriate for the
variables being analyzed.</p>
<p>Check (3/5): Solid effort. Hits all the elements. No clear mistakes.
Easy to follow (both the code and the output).</p>
<p>Check plus (5/5): Finished all components of the assignment correctly
and addressed both challenges. Code is well-documented (both
self-documented and with additional comments as necessary). Used
tidyverse, instead of base R. Graphs and tables are properly labelled.
Analysis is clear and easy to follow, either because graphs are labeled
clearly or you’ve written additional text to describe how you interpret
the output.</p>
</div>
